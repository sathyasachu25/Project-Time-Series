# Project-Time-Series
Advanced Time Series Forecasting with LSTM and Transformer Models (with Ablation Study)

ðŸ“Œ 1. Project Overview

This project focuses on building an advanced time series forecasting system using both traditional and modern deep learning approaches.
The goal is to:

Automatically generate a realistic multivariate time-series dataset

Perform full data preprocessing & windowing

Train two forecasting models:

Baseline LSTM

Transformer-based model with self-attention

Evaluate them using:

RMSE (Root Mean Squared Error)

MASE (Mean Absolute Scaled Error)

Conduct a full Ablation Study:

With different attention heads

With different encoder layers

This project demonstrates how deep learning and attention mechanisms improve forecasting accuracy over traditional sequence models.

ðŸ“Œ 2. Features of This Project

âœ” Synthetic multivariate dataset (trend + daily & weekly seasonality + noise)
âœ” Fully clean & imputed time-series
âœ” MinMax scaling
âœ” Sliding-window supervised dataset
âœ” LSTM baseline forecasting
âœ” Transformer encoder forecasting (self-attention)
âœ” RMSE & MASE evaluation
âœ” Graphs: prediction comparison
âœ” Ablation study for Transformer architecture
âœ” Results stored as CSV
âœ” Fully modular & well-documented code

ðŸ“Œ 3. Architecture Diagram (Simple)
Dataset â†’ Preprocessing â†’ Window Creation â†’ Models
                                      â†™         â†˜
                                   LSTM       Transformer
                                      â†˜         â†™
                                 Evaluation (RMSE, MASE)
                                             â†“
                                      Ablation Study

ðŸ“Œ 4. Dataset Description

The dataset is generated programmatically using:

Linear Trend

Daily Seasonality

Weekly Seasonality

Noise

Correlated Exogenous Features

Random Missing Values â†’ cleaned via forward/backward fill

Columns:

Column	Description
feature_1	Daily seasonality + noise
feature_2	Slow trend + noise
target	Weighted mix of trend, seasonality, exogenous effects

Dataset length default = 1500 timestamps with hourly frequency.

ðŸ“Œ 5. Data Preprocessing Pipeline

Forward-fill & backward-fill missing values

Train-val-test split (70% / 15% / 15%)

MinMax scaling on all features

Sliding window creation

X = past 48 values of all features  
y = next value of target  


Conversion to TensorFlow tf.data.Dataset objects

ðŸ“Œ 6. Models Used
ðŸ”¹ LSTM Baseline

Multi-layer LSTM

Dense regression head

Adam optimizer

Early stopping

Predicts 1-step ahead

ðŸ”¹ Transformer Encoder Model

Implemented from scratch:

Feature projection â†’ d_model

Sinusoidal positional encoding

Multi-head self-attention

Feed-forward network

Layer norm + residual connections

GlobalAveragePooling1D

Dense(1) output

This is the highlight of the project.

ðŸ“Œ 7. Evaluation Metrics
Metric	Meaning
RMSE	Measures typical size of errors
MASE	Scaled error compared to naive forecast

Both are computed on inverse-transformed predictions to ensure fair comparison.

ðŸ“Œ 8. Ablation Study

We vary:

Number of attention heads â†’ (2, 4)

Number of encoder layers â†’ (1, 2)

For each combination, we:

Train a new Transformer model

Evaluate RMSE & MASE

Append results into results/transformer_ablation.csv

Example output:

Model	Heads	Layers	RMSE	MASE
Transformer_h2_L1	2	1	X	X
Transformer_h4_L2	4	2	X	X
ðŸ“Œ 9. Project File Structure
project/
â”‚â”€â”€ Timeseries.py
â”‚â”€â”€ README.md
â”‚â”€â”€ results/
â”‚    â””â”€â”€ transformer_ablation.csv
â”‚â”€â”€ figures/
â”‚    â””â”€â”€ ltsm_vs_transformer_plot.png

ðŸ“Œ 10. How to Run the Project
Install Dependencies
pip install tensorflow numpy pandas scikit-learn matplotlib

Run the full project
python Timeseries.py


All results will be printed + saved automatically.

ðŸ“Œ 11. Outputs Generated

âœ” Model summaries (LSTM + Transformer)
âœ” Graph comparing predictions
âœ” RMSE + MASE values
âœ” Ablation study CSV
âœ” Synthetic dataset plotted (target series)

ðŸ“Œ 12. Key Findings (Example Summary)

Transformer model gave lower RMSE than LSTM

Ablation study showed:

Increasing attention heads improves performance

More encoder layers help but may overfit for small datasets

Self-attention captured long-term dependencies better than LSTM

ðŸ“Œ 13. Conclusion

This project demonstrates how attention-based architectures outperform classical LSTM models for time series forecasting. The Transformer effectively learns complex temporal dependencies using self-attention and provides better generalization on unseen data.

The ablation study provides insights into how architecture choices (heads, layers) influence performance.
