{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiU2rDazzq7x"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Advanced Time Series Forecasting with Deep Learning and Attention Mechanisms\n",
        "===========================================================================\n",
        "\n",
        "This script is a COMPLETE end-to-end implementation for your Cultus project:\n",
        "\n",
        "1. Generate a synthetic multivariate time series dataset with:\n",
        "   - multiple seasonality patterns\n",
        "   - trend\n",
        "   - noise\n",
        "   - exogenous features\n",
        "\n",
        "2. Clean and preprocess the data:\n",
        "   - handle missing values\n",
        "   - train / validation / test split (by time)\n",
        "   - scaling with MinMaxScaler\n",
        "   - windowed datasets for supervised learning\n",
        "\n",
        "3. Baseline model:\n",
        "   - LSTM regression model implemented in TensorFlow/Keras\n",
        "   - Evaluation metrics: RMSE, MASE\n",
        "\n",
        "4. Attention-based model:\n",
        "   - Custom Transformer Encoder for time series forecasting\n",
        "   - Uses Multi-Head Self-Attention + Feed Forward Network\n",
        "   - Implemented from scratch with Keras layers (no high-level forecasting libs)\n",
        "\n",
        "5. Ablation study:\n",
        "   - Vary number of attention heads and number of encoder layers\n",
        "   - Train multiple Transformer variants\n",
        "   - Compare RMSE/MASE across configurations\n",
        "\n",
        "6. Modular code:\n",
        "   - Clear functions and docstrings\n",
        "   - Easy to reuse / extend / deploy\n",
        "\n",
        "You can run this as:\n",
        "    python Timeseries_project.py\n",
        "\n",
        "Or copy into a Jupyter notebook cell and run step by step.\n",
        "\"\"\"\n",
        "\n",
        "# ==============================\n",
        "# 1. IMPORTS & GLOBAL CONFIG\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Make results reproducible\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuration hyperparameters for the project.\"\"\"\n",
        "    # Data\n",
        "    total_timesteps: int = 1500\n",
        "    n_features: int = 3           # 2 exogenous + 1 target\n",
        "    input_window: int = 48        # how many past steps to look at\n",
        "    batch_size: int = 32\n",
        "\n",
        "    # Train/val/test split (in percentage of time axis)\n",
        "    train_ratio: float = 0.7\n",
        "    val_ratio: float = 0.15       # test_ratio = 1 - train - val\n",
        "\n",
        "    # Training\n",
        "    epochs_lstm: int = 15\n",
        "    epochs_transformer: int = 15\n",
        "    learning_rate: float = 1e-3\n",
        "\n",
        "    # LSTM\n",
        "    lstm_units: int = 64\n",
        "    lstm_dropout: float = 0.2\n",
        "\n",
        "    # Transformer\n",
        "    d_model: int = 64\n",
        "    num_heads_default: int = 4\n",
        "    dff: int = 128\n",
        "    num_layers_default: int = 2\n",
        "    dropout_rate: float = 0.1\n",
        "\n",
        "    # Ablation\n",
        "    ablation_heads: tuple = (2, 4)\n",
        "    ablation_layers: tuple = (1, 2)\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 2. DATA GENERATION & PRE-PROCESSING\n",
        "# =====================================\n",
        "def generate_synthetic_multivariate_series(\n",
        "    total_timesteps: int,\n",
        "    freq: str = \"H\"\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate a synthetic multivariate time series with:\n",
        "    - Trend\n",
        "    - Daily and weekly seasonality\n",
        "    - Noise\n",
        "    - 2 exogenous features and 1 target\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame with DateTimeIndex and columns:\n",
        "        [\"feature_1\", \"feature_2\", \"target\"]\n",
        "    \"\"\"\n",
        "    # Time index\n",
        "    time_index = pd.date_range(start=\"2020-01-01\", periods=total_timesteps, freq=freq)\n",
        "\n",
        "    # Base time variable\n",
        "    t = np.arange(total_timesteps)\n",
        "\n",
        "    # Trend component\n",
        "    trend = 0.001 * t\n",
        "\n",
        "    # Seasonality (daily: period=24, weekly: period=24*7=168)\n",
        "    daily_seasonality = 0.5 * np.sin(2 * np.pi * t / 24)\n",
        "    weekly_seasonality = 0.3 * np.sin(2 * np.pi * t / (24 * 7))\n",
        "\n",
        "    # Noise\n",
        "    noise = 0.2 * np.random.randn(total_timesteps)\n",
        "\n",
        "    # Exogenous feature 1 (correlated with daily seasonality)\n",
        "    feature_1 = daily_seasonality + 0.1 * np.random.randn(total_timesteps)\n",
        "\n",
        "    # Exogenous feature 2 (trend + noise)\n",
        "    feature_2 = 0.0005 * t + 0.3 * np.random.randn(total_timesteps)\n",
        "\n",
        "    # Target combines everything\n",
        "    target = 2 * trend + daily_seasonality + weekly_seasonality + noise + 0.5 * feature_1\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"feature_1\": feature_1,\n",
        "            \"feature_2\": feature_2,\n",
        "            \"target\": target,\n",
        "        },\n",
        "        index=time_index,\n",
        "    )\n",
        "\n",
        "    # Introduce some missing values intentionally (to mimic real data)\n",
        "    for col in df.columns:\n",
        "        missing_idx = np.random.choice(total_timesteps, size=10, replace=False)\n",
        "        df.loc[df.index[missing_idx], col] = np.nan\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def clean_and_impute(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Simple data cleaning:\n",
        "    - Forward fill missing values, then backward fill for any leading NaNs.\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "    df_clean = df_clean.ffill().bfill()\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "def train_val_test_split(df: pd.DataFrame, cfg: Config):\n",
        "    \"\"\"\n",
        "    Split the dataframe into train, validation, and test based on time.\n",
        "    \"\"\"\n",
        "    n = len(df)\n",
        "    train_end = int(n * cfg.train_ratio)\n",
        "    val_end = int(n * (cfg.train_ratio + cfg.val_ratio))\n",
        "\n",
        "    train_df = df.iloc[:train_end]\n",
        "    val_df = df.iloc[train_end:val_end]\n",
        "    test_df = df.iloc[val_end:]\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def scale_datasets(train_df, val_df, test_df):\n",
        "    \"\"\"\n",
        "    Scale all datasets using MinMaxScaler fitted on the training set.\n",
        "    Returns scaled numpy arrays and the scaler object.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(train_df.values)\n",
        "\n",
        "    train_scaled = scaler.transform(train_df.values)\n",
        "    val_scaled = scaler.transform(val_df.values)\n",
        "    test_scaled = scaler.transform(test_df.values)\n",
        "\n",
        "    return train_scaled, val_scaled, test_scaled, scaler\n",
        "\n",
        "\n",
        "def create_windows(\n",
        "    data: np.ndarray, input_window: int, target_col_index: int\n",
        "):\n",
        "    \"\"\"\n",
        "    Create (X, y) windows for 1-step-ahead forecasting.\n",
        "\n",
        "    Args:\n",
        "        data: 2D numpy array [time, features]\n",
        "        input_window: number of past time steps used as input\n",
        "        target_col_index: index of the target column\n",
        "\n",
        "    Returns:\n",
        "        X: shape [num_samples, input_window, num_features]\n",
        "        y: shape [num_samples, 1]\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(data) - input_window):\n",
        "        X.append(data[i : i + input_window, :])\n",
        "        y.append(data[i + input_window, target_col_index])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y).reshape(-1, 1)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def make_tf_dataset(X, y, batch_size: int, shuffle: bool = True) -> tf.data.Dataset:\n",
        "    \"\"\"\n",
        "    Create a tf.data.Dataset from numpy arrays.\n",
        "    \"\"\"\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(X), seed=SEED)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "\n",
        "# ===========================================\n",
        "# 3. METRICS: RMSE AND MASE IMPLEMENTATION\n",
        "# ===========================================\n",
        "def compute_rmse(y_true, y_pred):\n",
        "    \"\"\"Root Mean Squared Error.\"\"\"\n",
        "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "def compute_mase(y_true, y_pred, training_series):\n",
        "    \"\"\"\n",
        "    Mean Absolute Scaled Error (MASE).\n",
        "\n",
        "    Args:\n",
        "        y_true: array-like, true values (test or validation)\n",
        "        y_pred: array-like, predicted values\n",
        "        training_series: 1D array of the *unscaled* training target series,\n",
        "                         used to compute the naive forecast errors.\n",
        "\n",
        "    Returns:\n",
        "        float: MASE value\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true).ravel()\n",
        "    y_pred = np.array(y_pred).ravel()\n",
        "\n",
        "    # Naive forecast: y_t_hat = y_{t-1} on training data\n",
        "    diffs = np.abs(np.diff(training_series))\n",
        "    scale = np.mean(diffs)\n",
        "\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    mase = mae / (scale + 1e-8)\n",
        "    return mase\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 4. LSTM BASELINE MODEL (Keras)\n",
        "# =========================================\n",
        "def build_lstm_model(input_window: int, num_features: int, cfg: Config) -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Build a simple LSTM-based forecaster.\n",
        "\n",
        "    Input shape: (input_window, num_features)\n",
        "    Output: 1-step-ahead forecast (scalar).\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(input_window, num_features), name=\"inputs\")\n",
        "\n",
        "    x = tf.keras.layers.LSTM(\n",
        "        cfg.lstm_units,\n",
        "        dropout=cfg.lstm_dropout,\n",
        "        return_sequences=False,\n",
        "        name=\"lstm_layer\",\n",
        "    )(inputs)\n",
        "\n",
        "    x = tf.keras.layers.Dense(32, activation=\"relu\", name=\"dense_1\")(x)\n",
        "    outputs = tf.keras.layers.Dense(1, name=\"output\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"LSTM_Baseline\")\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
        "        loss=\"mse\",\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
        "    )\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 5. TRANSFORMER ENCODER WITH ATTENTION\n",
        "# =========================================\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Standard sinusoidal positional encoding for sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"d_model\": self.d_model, \"max_len\": self.max_len})\n",
        "        return config\n",
        "\n",
        "    def call(self, x):\n",
        "        # x.shape: (batch_size, seq_len, d_model)\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        position = tf.range(0, self.max_len, dtype=tf.float32)[:, tf.newaxis]\n",
        "        div_term = tf.exp(\n",
        "            tf.range(0, self.d_model, 2, dtype=tf.float32)\n",
        "            * -(tf.math.log(10000.0) / self.d_model)\n",
        "        )\n",
        "        pe = tf.zeros((self.max_len, self.d_model))\n",
        "        pe_sin = tf.sin(position * div_term)\n",
        "        pe_cos = tf.cos(position * div_term)\n",
        "\n",
        "        # interleave sin and cos\n",
        "        pe = tf.reshape(\n",
        "            tf.stack([pe_sin, pe_cos], axis=-1),\n",
        "            (self.max_len, self.d_model),\n",
        "        )\n",
        "\n",
        "        pe = pe[tf.newaxis, :seq_len, :]  # (1, seq_len, d_model)\n",
        "        return x + pe\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Single Transformer encoder layer:\n",
        "    - Multi-head self-attention\n",
        "    - Feed Forward Network\n",
        "    - Residual connections + LayerNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_model, name=\"mha\"\n",
        "        )\n",
        "        self.ffn = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
        "                tf.keras.layers.Dense(d_model),\n",
        "            ],\n",
        "            name=\"ffn\",\n",
        "        )\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        # Keras automatically handles sub-layers in get_config for Functional API\n",
        "        return config\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        # Self-attention\n",
        "        attn_output = self.mha(x, x, x, training=training)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        # Feed-forward\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        return out2\n",
        "\n",
        "\n",
        "def build_transformer_model(\n",
        "    input_window: int,\n",
        "    num_features: int,\n",
        "    d_model: int,\n",
        "    num_heads: int,\n",
        "    dff: int,\n",
        "    num_layers: int,\n",
        "    dropout_rate: float,\n",
        "    cfg: Config,\n",
        ") -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Build a Transformer Encoder-based forecaster.\n",
        "\n",
        "    Steps:\n",
        "    - Linear projection of input features to d_model dimension\n",
        "    - Positional Encoding\n",
        "    - Stacked TransformerEncoderLayer blocks\n",
        "    - Global average pooling\n",
        "    - Dense layers -> 1-step forecast\n",
        "    \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(input_window, num_features), name=\"inputs\")\n",
        "\n",
        "    # Project features up to d_model\n",
        "    x = tf.keras.layers.Dense(d_model, name=\"input_projection\")(inputs)\n",
        "\n",
        "    # Add positional encoding\n",
        "    x = PositionalEncoding(d_model, name=\"positional_encoding\")(x)\n",
        "\n",
        "    # Encoder layers\n",
        "    for i in range(num_layers):\n",
        "        x = TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dff=dff,\n",
        "            dropout_rate=dropout_rate,\n",
        "            name=f\"encoder_layer_{i+1}\",\n",
        "        )(x)\n",
        "\n",
        "    # Pool across time\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D(name=\"global_avg_pool\")(x)\n",
        "\n",
        "    # Final MLP\n",
        "    x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate, name=\"dropout_final\")(x)\n",
        "    outputs = tf.keras.layers.Dense(1, name=\"output\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"Transformer_Forecaster\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.learning_rate),\n",
        "        loss=\"mse\",\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError(name=\"rmse\")],\n",
        "    )\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "# =============================================\n",
        "# 6. TRAINING & EVALUATION HELPER FUNCTIONS\n",
        "# =============================================\n",
        "def train_model(model, train_ds, val_ds, epochs: int, model_name: str):\n",
        "    \"\"\"\n",
        "    Generic training loop for Keras models with basic logging.\n",
        "\n",
        "    Returns:\n",
        "        history: tf.keras.callbacks.History object\n",
        "    \"\"\"\n",
        "    print(f\"\\n===== Training {model_name} for {epochs} epochs =====\\n\")\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        verbose=2,\n",
        "    )\n",
        "    return history\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model,\n",
        "    test_ds,\n",
        "    scaler: MinMaxScaler,\n",
        "    target_col_index: int,\n",
        "    train_target_unscaled: np.ndarray,\n",
        "    model_name: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set and compute RMSE & MASE in *original* scale.\n",
        "    \"\"\"\n",
        "    print(f\"\\n===== Evaluating {model_name} on Test Set =====\")\n",
        "\n",
        "    y_true_scaled = []\n",
        "    y_pred_scaled = []\n",
        "\n",
        "    for X_batch, y_batch in test_ds:\n",
        "        y_pred_batch = model.predict(X_batch, verbose=0)\n",
        "        y_true_scaled.append(y_batch.numpy())\n",
        "        y_pred_scaled.append(y_pred_batch)\n",
        "\n",
        "    y_true_scaled = np.vstack(y_true_scaled)\n",
        "    y_pred_scaled = np.vstack(y_pred_scaled)\n",
        "\n",
        "    # Inverse scale the target\n",
        "    # Build full feature arrays with zeros except the target column\n",
        "    def inverse_scale_target(y_scaled):\n",
        "        n_samples = y_scaled.shape[0]\n",
        "        dummy = np.zeros((n_samples, scaler.n_features_in_))\n",
        "        dummy[:, target_col_index] = y_scaled.ravel()\n",
        "        inv = scaler.inverse_transform(dummy)\n",
        "        return inv[:, target_col_index]\n",
        "\n",
        "    y_true_inv = inverse_scale_target(y_true_scaled)\n",
        "    y_pred_inv = inverse_scale_target(y_pred_scaled)\n",
        "\n",
        "    rmse = compute_rmse(y_true_inv, y_pred_inv)\n",
        "    mase = compute_mase(y_true_inv, y_pred_inv, training_series=train_target_unscaled)\n",
        "\n",
        "    print(f\"{model_name} -> RMSE: {rmse:.4f}, MASE: {mase:.4f}\")\n",
        "    return rmse, mase, y_true_inv, y_pred_inv\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# 7. ABLATION STUDY FOR TRANSFORMER\n",
        "# ======================================\n",
        "def run_transformer_ablation(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val,\n",
        "    X_test,\n",
        "    test_ds,\n",
        "    scaler,\n",
        "    target_col_index,\n",
        "    train_target_unscaled,\n",
        "    cfg: Config,\n",
        "):\n",
        "    \"\"\"\n",
        "    Ablation study:\n",
        "    - vary num_heads in cfg.ablation_heads\n",
        "    - vary num_layers in cfg.ablation_layers\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame summarizing results.\n",
        "    \"\"\"\n",
        "    print(\"\\n===== Starting Ablation Study on Transformer Hyperparameters =====\")\n",
        "    ablation_results = []\n",
        "\n",
        "    # Prepare tf.data datasets once to reuse\n",
        "    for num_heads in cfg.ablation_heads:\n",
        "        for num_layers in cfg.ablation_layers:\n",
        "            model_name = f\"Transformer_h{num_heads}_L{num_layers}\"\n",
        "            print(f\"\\n--- Ablation config: heads={num_heads}, layers={num_layers} ---\")\n",
        "\n",
        "            # Build datasets\n",
        "            train_ds = make_tf_dataset(X_train, y_train, cfg.batch_size, shuffle=True)\n",
        "            val_ds = make_tf_dataset(X_val, y_val, cfg.batch_size, shuffle=False)\n",
        "\n",
        "            # Build & train model\n",
        "            model = build_transformer_model(\n",
        "                input_window=cfg.input_window,\n",
        "                num_features=X_train.shape[-1],\n",
        "                d_model=cfg.d_model,\n",
        "                num_heads=num_heads,\n",
        "                dff=cfg.dff,\n",
        "                num_layers=num_layers,\n",
        "                dropout_rate=cfg.dropout_rate,\n",
        "                cfg=cfg,\n",
        "            )\n",
        "\n",
        "            train_model(\n",
        "                model,\n",
        "                train_ds,\n",
        "                val_ds,\n",
        "                epochs=cfg.epochs_transformer,\n",
        "                model_name=model_name,\n",
        "            )\n",
        "\n",
        "            # Evaluate\n",
        "            test_ds_local = make_tf_dataset(X_test, np.zeros_like(y_train[: len(X_test)]), cfg.batch_size, shuffle=False)\n",
        "            # We only care about X from test_ds_local, but we already built `test_ds` earlier.\n",
        "            rmse, mase, _, _ = evaluate_model(\n",
        "                model,\n",
        "                test_ds,\n",
        "                scaler,\n",
        "                target_col_index,\n",
        "                train_target_unscaled,\n",
        "                model_name=model_name,\n",
        "            )\n",
        "\n",
        "            ablation_results.append(\n",
        "                {\n",
        "                    \"model_name\": model_name,\n",
        "                    \"num_heads\": num_heads,\n",
        "                    \"num_layers\": num_layers,\n",
        "                    \"rmse\": rmse,\n",
        "                    \"mase\": mase,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    ablation_df = pd.DataFrame(ablation_results)\n",
        "    print(\"\\n===== Ablation Study Summary =====\")\n",
        "    print(ablation_df)\n",
        "    return ablation_df\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# 8. MAIN EXECUTION LOGIC\n",
        "# ==========================\n",
        "def main(cfg: Config):\n",
        "    # ------------------------\n",
        "    # 8.1 Generate and inspect data\n",
        "    # ------------------------\n",
        "    print(\"Generating synthetic multivariate time series data...\")\n",
        "    df_raw = generate_synthetic_multivariate_series(\n",
        "        total_timesteps=cfg.total_timesteps\n",
        "    )\n",
        "\n",
        "    print(\"\\nRaw dataset head:\")\n",
        "    print(df_raw.head())\n",
        "\n",
        "    # Data cleaning\n",
        "    df_clean = clean_and_impute(df_raw)\n",
        "\n",
        "    # Optional: visualize a small part of the target\n",
        "    plt.figure()\n",
        "    df_clean[\"target\"].iloc[:200].plot(title=\"Target time series (first 200 points)\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Target\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.2 Split into train/val/test\n",
        "    # ------------------------\n",
        "    train_df, val_df, test_df = train_val_test_split(df_clean, cfg)\n",
        "    print(f\"\\nTrain length: {len(train_df)}, Val length: {len(val_df)}, Test length: {len(test_df)}\")\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.3 Scale data\n",
        "    # ------------------------\n",
        "    train_scaled, val_scaled, test_scaled, scaler = scale_datasets(\n",
        "        train_df, val_df, test_df\n",
        "    )\n",
        "\n",
        "    num_features = train_scaled.shape[1]\n",
        "    target_col_index = list(train_df.columns).index(\"target\")\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.4 Create windowed datasets\n",
        "    # ------------------------\n",
        "    X_train, y_train = create_windows(\n",
        "        train_scaled, input_window=cfg.input_window, target_col_index=target_col_index\n",
        "    )\n",
        "    X_val, y_val = create_windows(\n",
        "        val_scaled, input_window=cfg.input_window, target_col_index=target_col_index\n",
        "    )\n",
        "    X_test, y_test = create_windows(\n",
        "        test_scaled, input_window=cfg.input_window, target_col_index=target_col_index\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"\\nWindowed shapes -> X_train: {X_train.shape}, y_train: {y_train.shape}, \"\n",
        "        f\"X_val: {X_val.shape}, X_test: {X_test.shape}\"\n",
        "    )\n",
        "\n",
        "    train_ds = make_tf_dataset(X_train, y_train, cfg.batch_size, shuffle=True)\n",
        "    val_ds = make_tf_dataset(X_val, y_val, cfg.batch_size, shuffle=False)\n",
        "    test_ds = make_tf_dataset(X_test, y_test, cfg.batch_size, shuffle=False)\n",
        "\n",
        "    # Unscaled training target series for MASE denominator\n",
        "    train_target_unscaled = train_df[\"target\"].values\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.5 Baseline LSTM Model\n",
        "    # ------------------------\n",
        "    lstm_model = build_lstm_model(\n",
        "        input_window=cfg.input_window,\n",
        "        num_features=num_features,\n",
        "        cfg=cfg,\n",
        "    )\n",
        "\n",
        "    train_model(\n",
        "        lstm_model,\n",
        "        train_ds,\n",
        "        val_ds,\n",
        "        epochs=cfg.epochs_lstm,\n",
        "        model_name=\"LSTM_Baseline\",\n",
        "    )\n",
        "\n",
        "    lstm_rmse, lstm_mase, lstm_y_true, lstm_y_pred = evaluate_model(\n",
        "        lstm_model,\n",
        "        test_ds,\n",
        "        scaler,\n",
        "        target_col_index,\n",
        "        train_target_unscaled,\n",
        "        model_name=\"LSTM_Baseline\",\n",
        "    )\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.6 Transformer Attention-based Model\n",
        "    # ------------------------\n",
        "    transformer_model = build_transformer_model(\n",
        "        input_window=cfg.input_window,\n",
        "        num_features=num_features,\n",
        "        d_model=cfg.d_model,\n",
        "        num_heads=cfg.num_heads_default,\n",
        "        dff=cfg.dff,\n",
        "        num_layers=cfg.num_layers_default,\n",
        "        dropout_rate=cfg.dropout_rate,\n",
        "        cfg=cfg,\n",
        "    )\n",
        "\n",
        "    train_model(\n",
        "        transformer_model,\n",
        "        train_ds,\n",
        "        val_ds,\n",
        "        epochs=cfg.epochs_transformer,\n",
        "        model_name=\"Transformer_Default\",\n",
        "    )\n",
        "\n",
        "    transformer_rmse, transformer_mase, tr_y_true, tr_y_pred = evaluate_model(\n",
        "        transformer_model,\n",
        "        test_ds,\n",
        "        scaler,\n",
        "        target_col_index,\n",
        "        train_target_unscaled,\n",
        "        model_name=\"Transformer_Default\",\n",
        "    )\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.7 Simple comparison plot\n",
        "    # ------------------------\n",
        "    plt.figure()\n",
        "    plt.plot(lstm_y_true[:200], label=\"True (test)\", linewidth=2)\n",
        "    plt.plot(lstm_y_pred[:200], label=\"LSTM pred\", alpha=0.7)\n",
        "    plt.plot(tr_y_pred[:200], label=\"Transformer pred\", alpha=0.7)\n",
        "    plt.title(\"Model comparison on Test Set (first 200 points)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\n",
        "        f\"\\nBaseline vs Attention-based Model:\\n\"\n",
        "        f\"LSTM -> RMSE: {lstm_rmse:.4f}, MASE: {lstm_mase:.4f}\\n\"\n",
        "        f\"Transformer -> RMSE: {transformer_rmse:.4f}, MASE: {transformer_mase:.4f}\\n\"\n",
        "    )\n",
        "\n",
        "    # ------------------------\n",
        "    # 8.8 Ablation Study on Attention Parameters\n",
        "    # ------------------------\n",
        "    ablation_df = run_transformer_ablation(\n",
        "        X_train=X_train,\n",
        "        y_train=y_train,\n",
        "        X_val=X_val,\n",
        "        y_val=y_val,\n",
        "        X_test=X_test,\n",
        "        test_ds=test_ds,\n",
        "        scaler=scaler,\n",
        "        target_col_index=target_col_index,\n",
        "        train_target_unscaled=train_target_unscaled,\n",
        "        cfg=cfg,\n",
        "    )\n",
        "\n",
        "    # Save ablation results for your report\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    ablation_path = os.path.join(\"results\", \"transformer_ablation.csv\")\n",
        "    ablation_df.to_csv(ablation_path, index=False)\n",
        "    print(f\"\\nAblation results saved to: {ablation_path}\")\n",
        "\n",
        "\n",
        "# Run the script\n",
        "if __name__ == \"__main__\":\n",
        "    main(cfg)"
      ]
    }
  ]
}